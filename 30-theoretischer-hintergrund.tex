\chapter{Konzeption der Suchfunktion}
Eine einfache Implementierung einer Suchfunktion kann aus drei Komponenten bestehen.
Aus dem Crawling, dem Index und dem Suchalgorithmus.
Das Crawling ist zuständig für das Finden von Dokumenten.
Der Index speichert Informationen der Dokumente, und die Suche ist zuständig für das Verstehen der Nutzeranfrage und die Abfrage der relevantesten Informationen aus dem Index, sowie dessen Verarbeitung und Darstellung.
Der Begriff Dokument wird hier verwendet, um die Dateien zu beschreiben, welche durch einen Crawler gesucht und durch den Index verarbeitet werden.
Unter Dokumenten können auch eine Website verstanden, welche durch einen Webcrawler durchsucht werden.
Es wird im Folgenden zunächst die Funktionsweise des Crawlings erläutert.
Danach werden zwei Möglichkeiten der Indizierung beschrieben.
Zuerst die Volltext-Indizierung, dann die Vektor-Indizierung.
Zuletzt werden die verschiedenen Arten von Suchalgorithmen erläutert.

\section{Crawling}
Bei der Implementierung eines Systems für eine Suchfunktion benötigt das System zunächst einen Datensatz von Dokumenten, welche über die Suchfunktion gefunden werden können.
Dieser wird mithilfe eines Crawlers aufgebaut.
Ein Crawler ist ein Algorithmus, welcher Techniken aus dem Natural Language Processing nutzt, um Informationen aus einem Dokument zu extrahieren.\cite{Khder_2021}
Implementierungen können reguläre Ausdrücke verwenden, um die Informationen zu extrahieren, oder auch fortgeschrittenere Verfahren, wie Abstract Syntrax Trees.
Im Falle von Websites kann der Crawler Hyperlinks zu weiteren Websites extrahieren.
Damit kann der Algorithmus sukzessive den Datensatz von Dokumenten befüllen.
Die neuen Dokumente werden durch den Index verarbeitet und wiederum auf neue Links analysiert.
Dieses Verfahren kann beliebig lange und beliebig rekursiv durchlaufen werden, um den Index zu erweitern.
Neben dem Crawling können Indizes befüllt werden, indem eine Liste von Dokumenten übergeben werden, welche dem Index hinzugefügt werden sollen.

\section{Indizierung}
Bei der Indexierung werden Wörter und Tokens mit Dokumenten assoziiert.
Dazu werden Wörter aus gecrawlten Dokumenten extrahiert und in die Datenbank geschrieben.
Den Dokumenten werden IDs zugeordnet und diese IDs werden den Wörtern zugeordnet.
Dem Index werden nun weitere Informationen hinzugefügt, wie die Wortfrequenz.
Die Wortfrequenz gibt an, wie oft ein Wort in einem Dokument vorkommt.
Es wird auch gespeichert, an welchen Stelle des Dokuments das Wort vorkommt, und auch in wie vielen Dokumenten ein Wort vorkommt.
Diese Art der Indizierung wird auch als invertierter Index bezeichnet, weil den Wörtern bzw.
Tokens die Dokumente zugeordnet werden, und nicht umgekehrt.
Wenn der Nutzer nun ein Keyword in die Suche eingibt, dann sind diese Keywords oft bereits im Index vorhanden, sodass die Dokumente, welche diese Keywords beinhalten einfach dem Index entnommen werden können.
Aufgabe der Suche ist es anschließend die Ergebnisse aufzubereiten.

\subsection{Volltext-Indizierung}
Bei der Indizierung der Wörter besteht die Problematik, dass gleiche Wörter in unterschiedlichen Formen existieren können.
So stammen \textit{Heizung} und \textit{heizen} beide von dem gleichen Wortstamm \textit{heiz} ab.
Um bei der Indizierung Speicherplatz zu sparen, können Wörter auf diesen Wortstamm reduziert werden, damit sie als ein einziges Wort betrachtet werden können.
Die Bildung des Wortstamms wird auch als Stemming bezeichnet.
Beim Stemming kann es jedoch zu Overstemming und Understemming kommen.
Overstemming bedeutet, dass zwei Wörter, die eigentlich nichts miteinander zu tun haben, also nicht semantisch gleich sind, den gleichen Wortstamm besitzen und als ein Wort betrachtet werden.
Ein Beispiel hierfür sind die Wörter \textit{Wand} und \textit{wandere}, wie in \textit{ich wandere}.
Beide besitzen den Wortstamm \textit{wand} und werden entsprechend als ein Wort betrachtet.
Understemming bedeutet, dass zwei Wörter, die eigentlich etwas miteinander zu tun haben, also semantisch gleich sind, nicht den gleichen Wortstamm besitzen und dadurch als zwei verschiedene Wörter betrachtet werden.
Ein Beispiel hierfür sind die Wörter \textit{absorbieren} und \textit{Absorption}, welche die Wortstämme \textit{absorb} und \textit{absorp} besitzen.
Es gibt Techniken zur Vermeidung solcher Probleme, wie der Einsatz vollständiger morphologischer Analysekomponenten.
Hierauf soll aber nicht weiter eingegangen werden.\\

Zur Implementierung eines Volltext-Index werden Dokumente und Wörter in einer m x n Matrix angeordnet, wobei m die Anzahl der Dokumente ist und n die Anzahl der Wörter.
Die Werte in dieser Matrix werden anhand einer ausgewählten Metrik bestimmt.
Eine oft verwendete Metrik ist das Verhältnis der Wortfrequenz mit der invertierten Dokumentfrequenz.
Die Wortfrequenz gibt dabei an, wie häufig das in dem Dokument vorkommt.
Die Dokumentfrequenz gibt an, in wie vielen Dokumente ein Wort vorkommt.
Das Verhältnis gibt damit an, wie charakteristisch das Wort für ein bestimmtes Dokument ist.
Wenn das Wort charakteristisch für ein Dokument ist, dann kommt es in diesem Dokument häufig vor, aber in anderen Dokumenten nur selten.
Wenn das Wort nicht charakteristisch für das Dokument ist, dann kommt es in anderen Dokumenten genauso häufig oder häufiger vor als in diesem Dokument.
Die Metrik wird auch als tf-idf-Wert bezeichnet.
TODO: Rechnung besser verstehen\\

\subsection{Vektor-Indizierung}
Neben einer Volltext-Indizierung können Dokumente in Form von Vektoren indiziert werden.
Dazu werden Dokumente zunächst, wie auch bei der Volltext-Indizierung gecrawlt.
Anschließend durchlaufen die Inhalte der Dokumente ein Preprocessing.
Dieses kann je nach Implementierung variieren.
Das Kapitel \textit{Einspielen der Daten in Weaviate} beschreibt, wie in der hier aufgeführten Implementierung das Preprocessing durchgeführt wird.
Das Preprocessing hat den Zweck die Daten an das Schema der Datenbank anzupassen und die Qualität der Daten zu erhöhen.
Außerdem sorgt es für eine kürzere Indizierungszeit.\\

Nach dem Preprocessing werden durch einen Transformer für die Inhalte der Dokumente Vektoren berechnet.
Ein Transformer wird mithilfe von Trainingsdaten darauf trainiert, Vektoren für Wörter zu generieren.
Das trainierte Modell wird nach dem Preprocessing durchlaufen.
Zuletzt werden die Daten in einer Vektordatenbank gespeichert.
Eine Vektordatenbank speichert Daten, wie eine dokumentenbasierte Datenbank.
Dort werden nun sowohl die rohen Daten als auch die Vektoren gespeichert, welche von dem Transformer berechnet wurden.
Die Vektoren haben den Vorteil, dass die Daten in der Datenbank nicht linear gespeichert sind.
Sie sind in einem n-dimensionalen Raum gespeichert, mit dessen Hilfe die semantische Nähe zwischen Dokumenten ausgedrückt werden kann.
Das funktioniert auf die gleiche Weise, wie bereits in dem Kapitel \textit{Semantic Search} beschrieben.

\section{Suchalgorithmen}
Im Folgenden werden zuerst gängige Suchalgorithmen erklärt, welche in nahezu jeder Suchfunktion zu finden sind.
Danach wird im speziellen auf die strukturierte Suche und die semantische Suche eingegangen.
Die semantische Suche wird später bei der Implementierung einer Suchfunktion verwendet werden.

\subsection{Die gängigen Suchalgorithmen}
In dem Kapitel \textit{Evaluationsmethoden und -Kriterien} wurde bereits beschrieben, dass eine Suche das Qualitätskriterium der Konformität erfüllen sollte.
Das bedeutet, dass eine Suchfunktion die gängigen Arten von Suchanfragen unterstützen muss.
Dieses Kapitel soll die Arten von Suchanfragen vorstellen.
Es ist wichtig diese zu kennen, um das Qualitätskriterium später bei der Implementierung erfüllen zu können.
Es gibt die gängigen Suchalgorithmen Keyword Search, Phrase Search, Boolean Search, Field Search.\\

Eine Keyword Search durchsucht Dokumente nach der Sucheingabe des Nutzers.
Die Eingabe wird dabei nicht als ganzes betrachtet, sondern jedes Wort einzeln.
Für jedes Keyword werden Dokumente als Ergebnis angezeigt, wenn dieses in dem Dokument vorhanden ist.
Wenn ein Dokument mehrere der Keywords beinhaltet, wird dessen Relevanz höher eingeschätzt als für Dokumente, welche weniger Keywords enthalten.
Dokumente mit höherer Relevanz werden weiter oben in der Ergebnisliste angezeigt.\\

Eine Phrase Search ist die Suche nach Textausschnitten in Dokumenten.
Hier werden nicht mehrere Keywords einzeln betrachtet, sondern die gesamte Eingabe in das Suchfeld als eine Einheit.
Es reicht also nicht mehr aus, dass ein Dokument eines der Wörter enthält.
Es muss die gesamte Sucheingabe als ein String enthalten sein.\\

Die Boolean Search bietet die Möglichkeit einen boolschen Ausdruck als Sucheingabe zu machen.
Ein Beispiel dafür ist die Sucheingabe \textit{Dokumentation AND Angular}.
Die Sucheingabe bedeutet, dass die Suchfunktion nur Dokumente als Ergebnis darstellen soll, welche beide Keywords Dokumentation und Angular enthalten.
Die Boolean Search kann auch eine Phrase, wie bei der Phrase Search, beinhalten: \textit{"Dokumentation von Software" AND Angular}.
In diesem Beispiel werden nur Dokumente als Ergebnis nur angezeigt, wenn sie den gesamten String \textit{Dokumentation von Software} enthalten, sowie das Keyword \textit{Angular}.
Bei einer Boolean Search können die boolschen Operatoren \textit{AND}, \textit{OR}, \textit{NOT} beliebig kombiniert werden.\\

Eine Field Search sucht Dokumente anhand von Attributen.
Der Nutzer kann diese Attribute auswählen.
Wenn der Nutzer beispielsweise ein Dokument sucht, welches am 01.01.2005 erstellt wurde, dann kann die Eingabe der Suche so aussehen: \textit{erstelldatum: 01.01.2005}.
Es können beliebig viele Attribute verwendet werden, um die Suche einzugrenzen.
Neben der Verwendung der Attribute für die Suche selbst, können die Attribute komplementär zu einer anderen Art von Suche verwendet werden.
So kann eine Suchfunktion Buttons bereitstellen, über welche Filter festgelegt werden.
Nun kann eine Keyword Search durchgeführt werden, aber die gefundenen Dokumente werden mithilfe der Filter weiter eingeschränkt.
Neben diesen gängigen Suchalgorithmen gibt es weitere Suchalgorithmen, wie die strukturierte Suche und die semantische Suche.

\subsection{Die strukturierte Suche}
Eine klassische Suchfunktion verwendet Keywords, um relevante Dokumente für eine Sucheingabe zu ermitteln.
Der Vorteil dieser Art von Suche ist, dass die technische Struktur, in der die Daten vorliegen und gespeichert sind, nicht bekannt sein müssen.
Der Nachteil ist auf der anderen Seite, dass die Suchergebnisse unpräzise sein können.
Wenn beispielsweise der Suchbegriff Kamera eingegeben wird, dann werden Kameras als Ergebnisse zurückgegeben.
Soll die Kamera nun bestimmte Eigenschaften besitzen, dann müssen diese Eigenschaften ebenfalls als Keywords angegeben werden.
Nun wird aber nicht die Suche auf Ergebnisse eingegrenzt, bei denen eine Kamera diese bestimmten Eigenschaften besitzt.
Stattdessen werden Suchergebnisse angezeigt, bei denen einige dieser Keywords vorkommen.
Demgegenüber stehen Datenbankabfragen, beispielsweise mithilfe von SQL.
Bei einer Datenbankabfrage können Objekte abgefragt werden, dessen Eigenschaften ganz bestimmte Werte haben.
Die Ergebnisse, die eine solche Abfrage zurückgibt, sind dabei vollkommen genau.
Es werden keine Objekte zurückgegeben, welche diese Kriterien nicht erfüllen.
Voraussetzung für eine solche Suchabfrage ist allerdings, dass die Struktur der Datenbank a priori bekannt ist.
Dem Nutzer muss der Name der Datenbank, der relevanten Tabellen, sowie der relevanten Properties bekannt sein, damit er das passende SQL für die Datenbankabfrage schreiben kann.
Strukturierte Suchen sollen die Vorteile beider Vorgehensweisen kombinieren.
Die Struktur der Daten soll a priori nicht bekannt sein müssen, aber trotzdem sollen die Suchergebnisse vollkommen präzise sein.
TODO: Wie wird das ermöglicht?

\subsection{Die Semantische Suche}
Unter einer semantischen Suche wird im Allgemeinen verstanden, dass die Suche nicht nur eine syntaktische Suche einer Zeichenkette ist, sondern auch Techniken, wie technische Analysen verwendet, um die Bedeutung der Sucheingabe nachzuvollziehen.\cite{Dengel_2012}
Eine semantische Suche hat den Zweck, die Ähnlichkeit und Beziehungen zwischen Wörtern zu verstehen.
Sie kennt Homonyme, Synoyme und Antonyme von Wörtern.  
So wird durch sie beispielsweise die Ähnlichkeit von den Wörtern \textit{rollout} \textit{deployment} abgebildet, und dass diese Wörter oft im gleichen Kontext verwendet werden.\\

Die technische Umsetzung einer semantischen Suche kann auf verschiedene Arten erfolgen.
Zum einen besteht die Möglichkeit ein explizites semantisches Netz heranzuziehen, und so die Zusammenhänge von Wörtern abzubilden.
Ein semantisches Netz ist eine Menge aus Aussagen in der Form \textit{Subjekt Prädikat Objekt}.
Anhand dieser Aussagen wird ein Graph aus Beziehungen zwischen Wörtern hergestellt.\cite{Lehmann}
TODO: Erläuterende Grafik + Beispiel.\\
Das hat den Vorteil, dass ein solches explizites semantisches Netz von Menschen erstellt wurde, und damit eine hohe Qualität der Daten einhergeht.
Denn an der Erstellung von semantischen Netzen sind mehrere Menschen beteiligt, welche zuerst einen Konsens über die Eigenschaften und Zusammenhänge von Wörtern schaffen müssen.
Der Nachteil dieser Methode ist der große Arbeitsaufwand, welcher mit der Erstellung eines solchen semantischen Netzes einhergeht.
Ein weiterer Nachteil ist die mögliche Unvollständigkeit, welche ein solches semantisches Netz besitzen könnte.
Eine Wissensdatenbank, welche für ein Projekt erstellt wurde, kann Definitionen von Begriffen beinhalten, welche in allgemeinen semantischen Netzen nicht vorhanden sind.
Bei der Umsetzung einer semantischen Suche mithilfe eines semantischen Netzes müsste also zuerst ein allgemeines semantisches Netz herangezogen werden, beispielsweise von DBPedia.
Anschließend müsste dieses semantische Netz um die neuen Definitionen, welche nur im Kontext des Projektes gelten, erweitert werden.\\

Eine weitere Möglichkeit zur Umsetzung einer semantischen Suche ist die Verwendung von Transformers und Vektordatenbanken.
Um zu verstehen, welche Wörter kontextuell zusammengehören, werden hier die Wörter in einem n-dimensionalen Raum positioniert.
Wörter, die sich sehr ähnlich sind, also im gleichen Kontext verwendet werden, haben in diesem n-dimensionalen Raum eine geringe Distanz zueinander.
Wörter, die sich eher unähnlich sind, wie \textit{"rollout" und "API"}, haben eine größere Distanz.
Der Vorteil einer semantischen Suche ist, dass der genaue Begriff, welcher gesucht wird nicht bekannt ist.
Wenn sich der Nutzer also über ein Thema informieren möchte, mit welchem er nicht gut vertraut ist, dann kann die semantische Suche hilfreich sein.
Denn der Nutzer kann nun einen Begriff eingeben, der zu dem Thema passt, und den er kennt.
Er findet anschließend Dokumente, welche vielleicht nicht genau diesen Begriff beinhalten, aber welche thematisch dennoch ähnlich sind.
Genau dieser Vorteil soll bei der Implementierung später genutzt werden.\\

Um eine semantische Suche zu implementieren, werden die Technologien von Transformern und Vektordatenbanken verwendet.
Ein Transformer erhält als Input eine große Menge an Text und mappt die einzelnen Wörter auf einen Vektor einer beliebigen Länge.
Der Vektor, der am Ende herauskommt, beschreibt die Position des Wortes in dem n-dimensionalen Raum.
Der Vektor beschreibt gewissermaßen, wie stark ein Wort in eine abstrakte Kategorie einzuordnen ist.
Jeder Wert im Vektor entspricht einer Kategorie.
Mithilfe der Vektoren können verschiedene Wörter hinsichtlich ihrer Ähnlichkeit analysiert werden.
Ähnliche Wörter habe eine große räumliche Nähe, während zwei Wörter, die in vollkommen unterschiedlichen Kontexten verwende werden eine sehr große Distanz im Raum besitzen.
Nehmen wir für ein Beispiel einen dreidimensionalen Raum an.
Die X-Achse ist beschriftet mit dem Wort „Tier“, die Y-Achse ist beschriftet mit dem Wort „Computer“ und die Z-Achse ist beschriftet mit dem Wort „Mensch“.
Nun geben wir einem Transformer das Wort „Katze“, und der Transformer berechnet einen dreidimensionalen Vektor, welcher das Wort „Katze“ im Raum positioniert.
Weil eine Katze ein Tier ist, ist der X-Wert des Vektors eins.
Der Wert eins bedeutet, dass das Wort vollständig zu dieser Kategorie gehört.
Da eine Katze überhaupt nichts mit einem Computer zu tun hat, ist der Y-Wert des Vektors 0.\\

Nun ist eine Katze kein Mensch, aber eine Katze ist ein Haustier von Menschen.
Es ist denkbar, dass die Wörter Katze und Mensch oft im gleichen Kontext verwendet werden, sodass der Wert bei 0,3 liegen könnte.
Damit der Transformer einen Vektor berechnen kann, braucht er eine Menge Daten.
Diese Daten erhält er aus vielen Texten.
Werden zwei Wörter oft im gleichen Text genannt oder kommen zwei Wörter in vielen Texten sehr nahe beieinander vor, dann geht der Transformer davon aus, dass die beiden Wörter ähnlich sind, und berechnet ähnliche Vektoren.
Zuvor müssen die Texte allerdings bereitgestellt werden.
Dazu kann beispielsweise das Internet gecrawlt werden.
Die Ergebnisse des Transformers werden in einer Vektordatenbank gespeichert.
Eine Vektordatenbank ist eine Datenbank, welche Vector Embeddings, also ein Objekt als Key und dessen Vektor als Value speichert.
Bei dem Objekt kann es sich um Wörter handeln, dann wird auch von Word Embeddings gesprochen.
Es können aber auch Daten andere Daten, wie Bilder, Videos oder Audio gespeichert werden.
Der Zweck von Vektordatenbanken ist es, Daten nicht einfach linear zu speichern, sondern in einem Raum.
Die Distanz zwischen zwei Einträgen in diesem Raum beschreibt dessen Ähnlichkeit.
Genau diese Informationen nutzen semantische Suchen.

\section{Wahl der Suchfunktion}
Aufgrund der Möglichkeit die Semantik einer Sucheingabe zu verstehen soll eine semantische Suche verwendet werden, um die neue Suchfunktion zu implementieren.
Wenn der Nutzer nicht genau weiß, wie eine Seite heißt, nach welcher er sucht, kann er sie bei einer semantischen Suche umschreiben, und trotzdem ein sinnvolles Ergebnis bekommen.
Aufgrund dessen sei angenommen, dass eine semantische Suche einer einfachen Keyword Search überlegen ist.\\

Bei der Implementierung sollen dabei keine semantischen Netze verwendet werden, sondern ein Vector Space Model.
TODO: Weiter ausführen

Des weiteren kann die semantische Suche mit weiteren Daten angereichert werden und damit verbessert werden.
Indem die Codebase, welche zu der Wissensdatenbank in Verbindung steht, ebenfalls indiziert wird, kann eine Traceability zwischen Code und Wissensdatenbank hergestellt werden.
Damit können Feature Location und Bug Localization umgesetzt werden.
Mit einer Architektur, welche ein Vector Space Model verwendet, kann also nicht nur eine überlegene Suche innerhalb der Wissensdatenbank implementiert werden, sondern die Suche kann um die Codebase erweitert werden, und damit können weitere Funktionen, wie Feature Location und Bug Localization ermöglicht werden.
Damit kann die Suchfunktion nicht nur zum Durchsuchen der Wissensdatenbank verwendet werden, sondern auch zum Durchsuchen der Codebase.
Und wenn in der Suchfunktion nach einem Feature gesucht wird, dann kann neben der Spezifikation in der Wissensdatenbank auch gleich der Einstiegspunkt im Code gefunden werden.
Damit verbessert sich wiederum die Wartbarkeit der Software, da das Ändern von Features oder korrigieren von Bugs erleichtert wird.