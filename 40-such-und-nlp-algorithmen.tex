\chapter{Such- und NLP-Algorithmen}

\section{Suchalgorithmen}

\subsection{Keyword Search}
TODO

\subsection{Phrase Search}
Eine Phrase Search ist die Suche nach Textausschnitten in Dokumenten.
Es werden also nicht mehrere Keywords einzeln betrachtet, sondern die Eingabe in das Suchfeld als Ganzen.
Anschließend wird in Dokumenten nach genau diesem Textausschnitt gesucht.

\subsection{Boolean Search}
TODO

\subsection{Field Search}
Eine Field Search sucht Dokumente anhand von Attributen.
Der Nutzer kann diese Attribute auswählen.
Wenn der Nutzer beispielsweise ein Dokument sucht, welches am 01.01.2005 erstellt wurde, dann kann die Eingabe der Suche so aussehen: "erstelldatum: 01.01.2005".
Es können beliebig viele Attribute verwendet werden, um die Suche einzugrenzen.\\

Neben der Verwendung der Attribute für die Suche selbst, können die Attribute komplementär zu einer anderen Art von Suche verwendet werden.
So kann eine Suchfunktion Buttons bereitstellen, über welche Filter festgelegt werden.
Nun kann eine Keyword Search durchgeführt werden, aber die gefundenen Dokumente werden mithilfe der Filter weiter eingeschränkt.

\subsection{Structured Search}
Eine klassische Suchfunktion verwendet Keywords, um relevante Dokumente für eine Sucheingabe zu ermitteln.
Der Vorteil dieser Art von Suche ist, dass die technische Struktur, in der die Daten vorliegen und gespeichert sind, nicht bekannt sein müssen.
Der Nachteil ist auf der anderen Seite, dass die Suchergebnisse unpräzise sein können.
Wenn beispielsweise der Suchbegriff Kamera eingegeben wird, dann werden Kameras als Ergebnisse zurückgegeben.
Soll die Kamera nun bestimmte Eigenschaften besitzen, dann müssen diese Eigenschaften ebenfalls als Keywords angegeben werden.
Nun wird aber nicht die Suche auf Ergebnisse eingegrenzt, bei denen eine Kamera diese bestimmten Eigenschaften besitzt.
Stattdessen werden Suchergebnisse angezeigt, bei denen einige dieser Keywords vorkommen.
Demgegenüber stehen Datenbankabfragen, beispielsweise mithilfe von SQL.
Bei einer Datenbankabfrage können Objekte abgefragt werden, dessen Eigenschaften ganz bestimmte Werte haben.
Die Ergebnisse, die eine solche Abfrage zurückgibt, sind dabei vollkommen genau.
Es werden keine Objekte zurückgegeben, welche diese Kriterien nicht erfüllen.
Voraussetzung für eine solche Suchabfrage ist allerdings, dass die Struktur der Datenbank a priori bekannt ist.
Dem Nutzer muss der Name der Datenbank, der relevanten Tabellen, sowie der relevanten Properties bekannt sein, damit er das passende SQL für die Datenbankabfrage schreiben kann.
Strukturierte Suchen sollen die Vorteile beider Vorgehensweisen kombinieren.
Die Struktur der Daten soll a priori nicht bekannt sein müssen, aber trotzdem sollen die Suchergebnisse vollkommen präzise sein.


\subsection{Lexical Search}
TODO

\subsection{Semantic Search}
Eine Semantische Suche arbeitet nicht anhand von Keywords, sondern anhand von Bedeutungen von Wörtern.
Sie versteht, dass einige Wörter sehr ähnlich sind, so wie "rollout" und "deployment", und dass diese Wörter oft im gleichen Kontext verwendet werden.
Um zu verstehen, welche Wörter kontextuell zusammengehören, werden die Wörter in einem n-dimensionalen Raum positioniert.
Wörter, die sich sehr ähnlich sind, also im gleichen Kontext verwendet werden, haben in diesem n-dimensionalen Raum eine geringe Distanz.
Wörter, die sich eher unähnlich sind, wie "rollout" und "API", haben eine größere Distanz.\\

Um eine semantische Suche zu implementieren, werden die Technologien von Transformern und Vektordatenbanken verwendet.
Ein Transformer bekommt als Input eine große Menge an Text und mappt die einzelnen Wörter auf einen Vektor einer beliebigen Länge.
Der Vektor, der am Ende herauskommt, beschreibt die Position des Wortes in dem n-dimensionalen Raum.
Der Vektor beschreibt gewissermaßen, wie stark ein Wort in eine abstrakte Kategorie einzuordnen ist.
Jeder Wert im Vektor entspricht einer Kategorie.
Mithilfe der Vektoren können verschiedene Wörter hinsichtlich ihrer Ähnlichkeit analysiert werden.
Ähnliche Wörter habe eine große räumliche Nähe, während zwei Wörter, die in vollkommen unterschiedlichen Kontexten verwende werden eine sehr große Distanz im Raum besitzen.
Nehmen wir für ein Beispiel einen dreidimensionalen Raum an.
Die X-Achse ist beschriftet mit dem Wort „Tier“, die Y-Achse ist beschriftet mit dem Wort „Computer“ und die Z-Achse ist beschriftet mit dem Wort „Mensch“.
Nun geben wir einem Transformer das Wort „Katze“, und der Transformer berechnet einen dreidimensionalen Vektor, welcher das Wort „Katze“ im Raum positioniert.
Weil eine Katze ein Tier ist, ist der X-Wert des Vektors eins.
 Der Wert eins bedeutet, dass das Wort vollständig zu dieser Kategorie gehört.
Da eine Katze überhaupt nichts mit einem Computer zu tun hat, ist der Y-Wert des Vektors 0.
Nun ist eine Katze zwar kein Mensch, aber eine Katze ist ein Haustier von Menschen.
Es ist denkbar, dass die Wörter Katze und Mensch oft im gleichen Kontext verwendet werden, sodass der Wert bei 0,3 liegen könnte.
Damit der Transformer einen Vektor berechnen kann, braucht er eine Menge Daten.
Diese Daten erhält er aus vielen Texten.
Werden zwei Wörter oft im gleichen Text genannt oder kommen zwei Wörter in vielen Texten sehr nahe beieinander vor, dann geht der Transformer davon aus, dass die beiden Wörter ähnlich sind, und berechnet ähnliche Vektoren.
Zuvor müssen die Texte allerdings bereitgestellt werden.
Dazu kann beispielsweise das Internet gecrawlt werden.
Die Ergebnisse des Transformers werden in einer Vektordatenbank gespeichert.
Eine Vektordatenbank ist eine Datenbank, welche Vector Embeddings, also ein Objekt als Key und dessen Vektor als Value speichert.
Bei dem Objekt kann es sich um Wörter handeln, dann wird auch von Word Embeddings gesprochen.
Es können aber auch Daten andere Daten, wie Bilder, Videos oder Audio gespeichert werden.
Der Zweck von Vektordatenbanken ist es, Daten nicht einfach linear zu speichern, sondern in einem Raum.
Die Distanz zwischen zwei Einträgen in diesem Raum beschreibt dessen Ähnlichkeit.
Genau diese Informationen machen sich semantische Suchen zu Nutze.

\section{NLP-Algorithmen}

TODO