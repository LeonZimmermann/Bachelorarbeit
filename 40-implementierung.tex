\chapter{Implementierung der neuen Suchfunktion}
In diesem Kapitel wird die Implementierung einer alternativen Suchfunktion zu der Suchfunktion von Confluence dargestellt.
Diese Implementierung wird anschließend mithilfe des erläuterten Versuchsaufbaus mit der bestehenden Suche von Confluence verglichen.
Die Implementierung verwendet eine Vektordatenbank, welche eine semantische Suche ermöglicht.
Das Filtern nach bestimmten Properties ermöglicht die Vektordatenbank ebenfalls.
Es wird die Vektordatenbank Weaviate verwendet.
Der Vergleich zeigt, ob eine semantische Suchfunktion \textit{besser} ist als die Confluence-Suche.

\section{Aufsetzen der Vektordatenbank Weaviate}
Für das Aufsetzen von Weaviate werden zwei Komponenten benötigt.
Zum einen die Vektordatenbank selbst.
Zum anderen ein Transformer, welcher Text entgegennimmt, und diese in Vektoren umwandelt, sodass diese in der Datenbank gespeichert werden können.
Um die beiden Komponenten aufzusetzen wird Docker verwendet.
Das entsprechende docker-compose-yml File ist im Anhang zu finden.
Hier werden die beiden Komponenten definiert.
Unter \textit{t2v-transformers} wird der Transformer konfiguriert.
Es wird das Image eines bereits vortrainierten Transformers verwendet.
Unter \textit{weaviate} wird die Datenbank konfiguriert.
Hier wird mithilfe von den Environment-Variablen \textit{$DEFAULT\_VECTORIZER\_MODULE$}, \textit{$ENABLE\_MODULES$} und \textit{$TRANSFORMERS\_INFERENCE\_API$} konfiguriert, welcher Transformer verwendet werden soll.
So wird konfiguriert, dass der Transformer der anderen Komponente verwendet werden soll.\\

Mithilfe der Dependency \textit{io.weaviate:client:4.0.1} wird die Client API von Weaviate verwendet.
So wird nun eine Verbindung zu der Vektordatenbank aufgebaut.
Diese beinhaltet zu diesem Zeitpunkt noch keine Daten.
Bevor die Daten in die Datenbank eingespielt werden, muss das Schema der Daten angegeben werden.
Der entsprechende Code ist ebenfalls im Anhang zu finden.
Es wird eine Klasse \textit{Document} definiert.
Diese Klasse beinhaltet die Properties \textit{documentUrl}, \textit{h1}, \textit{h2} und \textit{p}.
Es werden in dieser Klasse also die URL des Dokuments, sowie die Inhalte aller h1-, h2 und p-Tags gespeichert.
Außerdem wird als Vectorizer \textit{text2vec-transformers} konfiguriert.\\

\section{Einspielen der Daten in Weaviate}
Um nun die Daten aus Confluence in Weaviate einzuspielen, werden zuerst die Daten aus Confluence exportiert.
Beim Export von Confluence Seiten werden HTML-Dateien generiert.
Es werden keine CSS-, JavaScript- oder Bilddateien generiert.
Hierdurch entstehen bei der Durchführung der Studie Probleme, auf welche später eingegangen wird.
Die HTML-Dateien werden preprocessed, um dem zuvor definierten Schema zu entsprechen.
Es werden zuerst mithilfe von regulären Ausdrücken alle Inhalte von h1-, h2- und p-Tags herausgefiltert.
Anschließend werden Punctuations und Stopwords entfernt und die Inhalte druchlaufen einen Tokenizer und einen Stemmer.
Punctuations sind Zeichen, wie die folgenden: \textit{.,;:}.
Stopwords sind Wörter, welche für einen Leser notwendig sind, aber für die Verarbeitung durch einen Algorithmus als unwichtig erachtet werden\cite{Sarica_Luo_2021}.
Beispiele für Stopwords sind \textit{aber, denn, der}.
Ein Tokenizer trennt einen Text in einzelne Wörter auf.
Aus einem Text, wie \textit{das deployment erfolgt durch ein bash-skript} wird also ein Array, welches folgendermaßen aussieht:\\

\(["das", "deployment", "erfolgt", "durch", "ein", "bash", "skript"]\).\\

Ein Stemmer bestimmt den Wortstamm für die einzelnen Wörter auf Basis von Grammatikregeln.
Konkret verwendet die Software den Porter-Stemmer-Algorithmus.
Aus dem Wort \textit{deployment} wird dadurch beispielsweise \textit{deploy}.
Duplikate von Wörtern werden anschließend verworfen.
Nachdem die Inhalte dieses Preprocessing durchlaufen haben, werden sie in die Datenbank eingespielt.\\

Im Kapitel \textit{Vektorindizes} wurde bereits von Performancegründen gesprochen, aus denen das Preprocessing durchgeführt wird.
Da nun die einzelnen Schritte des Preprocessings erklärt wurde, kann auch erklärt werden, warum das Preprocessing die Performance beim indizieren erhöht.
Zuallererst werden viele Wörter gänzlich verworfen, weil sie Stopwords sind.
Durch den Stemmer werden anschließend ähnliche Wörter zusammengruppiert.
Die Wörter \textit{Heizung} und \textit{heizen} stammen beide vom gleichen Wortstamm \textit{heiz}.
Das bedeutet, dass aus zwei verschiedenen Wörtern, welche beide indiziert werden müssen, ein einziges Wort gemacht wird.
Denn am Ende werden Duplikate, wie bereits erwähnt, verworfen.
Die Anzahl der Wörter, welche indiziert werden müssen, wird dadurch reduziert, und damit auch die Last auf dem Transformer, welche die Vektoren für die Wörter berechnen muss.

\section{Verwendung der Suchfunktion von Weaviate}
Weaviate verwendet eine API, welche GraphQL queries entgegennimmt.
Um eine Suche durchzuführen muss ein GET-Request durchgeführt werden.
Nun muss angegeben werden, welche Klasse aus der Datenbank abgefragt werden soll.
In diesem Fall \textit{Document}.

\subsection{Verwendung der Semantische Suche}
Um die semantische Suche zu verwenden, muss die NearText Funktion verwendet werden.

\subsection{Verwendung von Filtern}
TODO: Ergänzen

\subsection{Die Benutzeroberfläche}