\chapter{Zusammenfassung und Ausblick}
In dem letzten Kapitel wurde der Vergleich zwischen der Confluence-Suche und der neuen Suchfunktion durchgeführt.
Die Ergebnisse sind ebenfalls diskutiert worden.
Dieses Kapitel die fasst die Arbeit zusammen und stellt einen Ausblick dar.

\section{Zusammenfassung}
Zweck der Arbeit war die Konzeption einer neuen Suchfunktion, welche nach festgelegten Kriterien besser ist als die Confluence-Suchfunktionen.
Dazu wurden in \myRef{Kapitel}{chap:anwendungsfaelle} Anwendungsfälle definiert, anhand dessen die Nutzung der Suchfunktionen konkretisiert wurde.
Dies hat den Rahmen geschaffen, um später einen Vergleich der beiden Suchfunktionen durchführen zu können.
Nach der Definition der Anwendungsfälle, wurde die Technologie der Suchfunktion von Confluence in \myRef{Kapitel}{chap:technologie-von-confluence} erläutert.
Damit wurde ein besseres Verständnis für die Suchfunktion von Confluence geschaffen.
Dieses bessere Verständnis war die Grundlage für die Konzeption einer neuen Suchfunktion in \myRef{Kapitel}{chap:konzeption-der-suchfunktion}.
Denn das Verständnis war notwendig, um Schwachstellen in der Confluence-Suche zu identifizieren und Verbesserungspotenziale zu verstehen.
In \myRef{Kapitel}{chap:konzeption-der-suchfunktion} wurde zuerst die Technologie der neuen Suchfunktion erörtert.
Während Confluence einen Volltext-Index verwendet, verwendet die neue Suchfunktion Sentence Transformer für die Indizierung.
Dazu wird eine Vektordatenbank benötigt, sowie der Scoring Algorithmus HNSW.
Auf Grundlage der Verbesserungspotenziale der Confluence-Suche und der dargestellten alternativen Technologien, wurde die neue Suchfunktion abgeleitet.
Dazu wurde argumentiert, warum sich die dargestellten Technologien als eine Alternative zu der bestehenden Confluence-Suche eignen sollen.
% TODO: Welche Quellen sind das:
Es wurde anhand verschiedener Quellen belegt, dass eine semantische Suche auf Basis von Sentence Transformers gute Ergebnisse für Open-Domain Datensätze erzielen. 
Dann wurde die Implementierung der neuen Suchfunktion in \myRef{Kapitel}{chap:implementierung} erklärt.\\

Nachdem die neue Suchfunktion implementiert wurde, wurden die Precision-Werte für einen angefertigten Datensatz zwischen den beiden Suchfunktionen verglichen.
Das nötige Wissen für diesen Vergleich wurde in \myRef{Kapitel}{chap:evaluationsmethoden} erläutert.
Es wurde ebenfalls auf alternative Möglichkeiten zur Messung der Performance von Suchfunktionen eingegangen.
Der angefertigte Datensatz leitete sich dabei aus den dargestellten Anwendungsfällen aus \myRef{Kapitel}{chap:anwendungsfaelle} ab.
Der Datensatz entstammte aus einer Wissensdatenbank eines Softwareprojektes.
Die Software soll im Gesundheitswesen eingesetzt werden und umfasste entsprechend Fachbegriffe aus dem Gesundheitswesen.
Darüber hinaus beinhaltet die Wissensdatenbank Definitionen, welche sich spezifisch auf das Softwareprojekt beziehen.\\

Die Durchführung der Studie wurde in \myRef{Kapitel}{chap:vergleich-der-suchfunktionen} erklärt.
Die Studie kam zu dem Ergebnis, dass die neue Suchfunktion eine wesentlich schlechtere Performance besitzt als die Confluence-Suche.
Begründet wurde dieses Ergebnis mit der Tatsache, dass es sich bei dem Datensatz, welcher in der Studie verwendet wurde, um eine Closed-Domain handelt.
Da der Sentence Transformer nicht fine-tuned wurde, kennt der Sentence Transformer die domänenspezifischen Fachbegriffe nicht und kann daher keine passenden Vektoren generieren, welche dessen Semantik wiederspiegeln.
Im Ausblick wird erläutert, welche Ansätze es in der Literatur gibt, um dieses Problem zu lösen.

\section{Ausblick}
\label{chap:ausblick}
Die Studie hat ergeben, dass die semantische Suche, so wie sie implementiert war, nicht besser ist als eine Suche auf Basis von BM25.
Der Kontext, in welchem die Suchen verwendet werden, ist eine Closed-Domain und beinhaltet domänenspezifische Fachbegriffe.
Probablistische Modelle unterscheiden sich in der Performance nicht zwischen Closed-Domain und Open-Domain.
Grund dafür ist, dass probablistische Modelle die Dokumente ohne ein vorheriges Training indizieren, anders als dies bei Sentence Transformern der Fall ist. 
So könnte der Schluss gezogen werden, dass sich probablistische Modelle besser für Closed-Domain Datensätze eignen.
Dennoch gibt es in der Literatur Ansätze, um die Probleme von Sentence Transformern mit Closed-Domain Datensätzen zu beheben.
In der Literatur wird dabei von Domain Adaption oder von Fine-Tuning gesprochen.
Gururangan et al. (\citeyear{Gururangan_Marasović_Swayamdipta_Lo_Beltagy_Downey_Smith_2020}) zeigen beispielsweise, dass eine weitere Phase des pre-trainings zur Adaption an eine Domäne Performance Verbesserungen mit sich bringt.
Dazu führen sie das pre-training fort, auf einem unlabeled Datensatz von domänenspezifischen Texten.\\

Wang et al. (\citeyear{Wang_Thakur_Reimers_Gurevych_2022}) entwickelten das sogenannte Generative Pseudo Labeling, um Sentence Transformer an eine Domäne anzupassen.
Zuerst extrahieren sie Paragraphen aus der Domäne, an welche der Sentence Transformer angepasst werden soll.
Anschließend generieren sie automatisch drei Sucheingaben für jeden Paragraphen.
Diese Sucheingaben werden an einen bestehenden Dense Retriever gesendet.
Ein Dense Retriever ist dabei eine Vektordatenbank mit einem entsprechenden Sentence Transformer zum Indizieren der Daten und einem Scoring Algorithmus, wie HNSW. 
Nun werden die Ähnlichkeiten der Sucheingaben mit den Paragraphen mithilfe eines Cross-Encoders bestimmt.
Ein Cross-Encoder ist ein Sentence Transformer, welcher zwei Sätze entgegennimmt und die Ähnlichkeit der beiden Sätze bestimmt.
Er funktioniert anders als der Bi-Encoder, welcher für die Implementierung der neuen Suchfunktion verwendet wurde.
Denn dieser generiert für jeden Satz zuerst Embeddings, welche anschließend mithilfe des Scoring-Algorithmus verglichen werden.
Nun werden die berechneten Ähnlichkeiten zusammen mit den Sucheingaben und Paragraphen als pseudo-gelabelte Trainingsdaten verwendet.
Der Sentence Transformer, welcher an eine Domäne angepasst werden soll, wird mithilfe der MarginMSE-Loss Funktion auf die generierten Trainingsdaten trainiert.\\  

% TODO: TSDAE
% Außerdem untersuchen Wang et al. (\cite{Wang_Reimers_Gurevych_2021}).