\chapter{Einleitung}
\label{chap:intro}

Die Einleitung beschreibt die Struktur der Arbeit, sodass dem Leser gleich zu Beginn der rote Faden ersichtlich wird.
Dazu wird im Kapitel Motivation zuerst erläutert, warum der Inhalt der Arbeit von Relevanz ist.
Das Kapitel beschreibt das Problem, welches Softwareentwickler in der täglichen Arbeit mit Wissensdatenbanken haben.
Das nächste Kapitel "Ziele der Arbeit" gibt eine Übersicht darüber, was diese Arbeit erreichen möchte.
Das Kapitel erklärt, wie das Problem, welches in der Motivation beschrieben wurde, in dieser Arbeit systematisch gelöst wird.
Dazu sollen vier Teilziele erreicht werden.
Wie diese vier Teilziele erreicht werden wird in dem Kapitel "Vorgehensweise" erklärt.
Das Kapitel beschreibt für jedes Teilziel kurz und knapp dessen Vorgehensweise.
Im darauffolgenden Kapitel werden die Verwandten Arbeiten beleuchtet.
Zuletzt wird die Arbeit in dem Kapitel "Abgrenzungen" inhaltlich abgegrenzt.

\section{Motivation}
Suchfunktionen sind in vielen Anwendungen vorhanden und können einen großen Einfluss auf die Erfahrung von Nutzern haben.
Google ist ein Anbieter einer bekannten Suchfunktion.
Sie wird verwendet, um im World Wide Web die passende Website für eine Suchanfrage zu finden.
Die Suchanfrage besteht dabei meistens aus lediglich ein bis drei Keywords (\citeauthor[S. 18]{Sirotkin_2012}).
Es ist nicht einfach für diese Keywords die Websites zu identifizieren, welche für einen Nutzer am passendsten ist.\\

Auch andere Arten von Anwendungen verwenden Suchfunktionen, darunter Wissensdatenbanken, wie beispielsweise Confluence.
In Wissensdatenbanken werden Informationen auf Seiten gespeichert, welche über die Suchfunktion auffindbar sein sollen.
Softwareentwickler haben bei der Arbeit mit Wissensdatenbanken, insbesondere bei der Arbeit mit Spezifikationen und Dokumentationen, oft das Problem, dass die gesuchten Inhalte nicht gefunden werden können.
Das kann daran liegen, dass die gefundenen Ergebnisse zu spezifisch sind, z.B. wenn eine allgemeine Definition von Domänenobjekten gesucht wird, aber eine Spezifikation eines Use-Cases gefunden wird, in welchem das Domänenobjekt lediglich erwähnt wird.
Außerdem haben manche Wissensdatenbanken Schwierigkeiten, die Semantik einer Suchanfrage zu verstehen.
Wird also nach einem Suchbegriff, wie „deployment“ gesucht, dann werden keine Ergebnisse gefunden, welche Wörter, wie „rollout“ beinhalten, auch wenn es sich hierbei um den gleichen Prozess handelt.
Softwareentwickler müssen also das genaue Wording in der Dokumentation kennen, um ein sinnvolles Ergebnis angezeigt zu bekommen, und es reicht nicht aus, ein thematisch ähnliches Wort in die Suche einzugeben.
% Motivation Deprecated-Inhalte: Weiterhin werden oftmals Inhalte angezeigt, welche bereits als deprecated markiert sind, und für aktuelle Versionen der Software keine Relevanz mehr haben. 
Ziel dieser Arbeit soll es sein, mithilfe von Wissen über Suchalgorithmen und Algorithmen aus dem Natural Language Processing, diese Probleme zu lösen, sodass Softwareentwickler in Zukunft besser die Inhalte finden, nach denen sie tatsächlich gesucht haben.

\section{Ziele der Arbeit}
In der Motivation sind bereits Probleme genannt worden, die ein Softwareentwickler bei der Verwendung von Suchfunktionen in Wissensdatenbanken hat.
Manchmal ist das Abstraktionslevel der gefundenen Informationen nicht das, welches sich der Softwareentwickler gewünscht hat.
Manchmal kennt der Softwareentwickler nicht das genaue Wording, um die gewünschten Informationen zu finden.
Ziel der Arbeit ist es diese Probleme zu lösen.\\

Zur Erreichung des Hauptziels der Arbeit werden folgende Teilziele definiert:
\begin{itemize}
   \item \textbf{Teilziel 1:}
         Es werden Lösungsansätze zur Verbesserung von Suchfunktionen herausgearbeitet.
   \item \textbf{Teilziel 2:}
         Es werden Methoden für die Bewertung der Lösungsansätze herausgearbeitet.
         Damit wird die Frage beantwortet, wann eine Suchfunktion "gut" ist.
   \item \textbf{Teilziel 3:}
         Es wird die Theorie zur Implementierung der Lösungsansätze erläutert.
   \item \textbf{Teilziel 4:}
         Es werden die Lösungsansätze anhand der Evaluationsmethoden bewertet, mit einer bestehenden Suchfunktion verglichen und es wird ein Fazit gezogen.
\end{itemize}

\section{Vorgehensweise}
Die Vorgehensweise ist im Folgenden entsprechend der Teilziele in vier Schritte eingeteilt.
Jeder Schritt in der Vorgehensweise addressiert ein Teilzeil.

\subsection*{Adressierung von Teilziel 1}
Zunächst werden die Lösungsansätze herausgearbeitet indem die konkreten genannten Probleme weiter beleuchtet und unterteilt werden.
Sie werden in mehreren Use-Cases formuliert.

\subsection*{Adressierung von Teilziel 2}
Um die Lösungsansätze zu bewerten wird erörtert, wie die Performance einer Suchfunktion evaluiert werden kann.
Die Lösungsansätze sollen auf ihre Effektivität geprüft werden.
Die Effektivität zu bestimmen ist nur mit geeigneten Messmethoden möglich.
Diese Effektivität soll mit einer bestehenden Suchfunktion verglichen werden.

TODO Was bedeutet Effektivität in diesem Kontext?

\subsection*{Adressierung von Teilziel 3}
Die theoretische Implementierung der Lösungsansätze wird als nächstes erläutert.
Dazu werden auch die theoretischen Grundlagen für die Implementierung behandelt.
Außerdem werden verschiedene Arten von Suchfunktionen vorgestellt.
Zusätzlich werden Methoden vorgestellt, um die Suche, unabhängig von der gewählten Methode zu verbessern.
Und es werden Methoden zur Aufbereitung der Informationen vorgestellt.
Damit werden die gesuchten Ergebnisse auf eine Art und Weise dargestellt, welche dem Softwareentwickler gleich die gewünschten Informationen liefert.

\subsection*{Adressierung von Teilziel 4}
Um ein Fazit zu ziehen muss bewertet werden, ob die Lösungsansätze ihren Zweck erfüllen.
Dazu wurden zunächst die Evaluationsmethoden erörtert.
Diese werden in diesem Schritt angewandt.
Die Evaluationsmethoden liefern Metriken anhand dessen die Performance der Lösungsansätze bewertet wird.
Diese Performance wird verglichen mit einer bestehenden Suche.
Damit kann im Fazit diskutiert werden, ob die Lösungsansätze ihren Zweck erfüllt haben.

\section{Verwandte Arbeiten}

Es gibt einige Arbeiten, welche die gleichen oder sehr ähnliche Probleme adressieren.\\

% Quelle: Automatic Query Reformulations for Text Retrieval in Software Engineering
So wird in "Automatic Query Reformulations for Text Retrieval in Software Engineering" von Haiduc et. al. ein System zur Verbesserung von Suchanfragen vorgeschlagen.
Ausgangspunkt für das Paper ist das Problem der Traceability zwischen Code und anderen Softwareentwicklungs-Artefakten.
Traceability bedeutet, dass sich von einer Stelle im Code, auf die entsprechenden Stellen in anderen Artefakten zurückschließen lässt.
Ein Anwendungsfall für eine solche Traceability-Funktionalität ist "Feature Location", also das finden der Spezifikation eines Features, wenn nur der Code vorhanden ist.
Das System, welches von Haiduc et. al. vorgeschlagen wird, verwendet Query Reformulations, um die Traceability herzustellen.
Query Reformulation bedeutet, dass das System den Softwareentwickler bei der Eingabe einer Suchanfrage zur Suche nach den passenden Artefakten unterstützt.
Dazu gibt der Softwareentwickler zunächst eine Suchanfrage ein, und markiert diejenigen Ergebnisse, welche am relevantesten für ihn sind.
Auf Grundlage der gewählten Ergebnisse und mithilfe eines Machine Learning Algorithmus werden nun Vorschläge für eine verbesserte Suchanfrage gemacht.
Dabei gibt es verschiedene Strategien.
Wenn der Softwareentwickler zu Beginn eine sehr lange Suchanfrage eingegeben hat, dann kann das System eine Reduktion der Suchanfrage vorschlagen.
Hat der Softwareentwickler dagegen lediglich einen Suchbegriff angegeben, so kann das System eine Erweiterung der Suchbegriffe vorschlagen.
Dazu greift das System auf Synonyme des eingegebenen Suchbegriffes zurück.\\

In dem Paper "From Word Embeddings To Document Similarities for Improved Information Retrieval in Software Engineering" von Ye et. al. wird beschrieben, wie Word Embeddings dazu verwendet werden können, um Traceability zwischen Code und anderen Softwareentwicklungs-Artefakten herzustellen.
Word Embeddings sind eine Datenstruktur, welche einem Wort einen Vektor in einem n-dimensionalen Raum zuweist.
Anhand dieses Vektors kann die Ähnlichkeit zwischen Wörter beschrieben werden.
Ähnliche Wörter haben eine geringe Distanz im n-dimensionalen Raum.
Unähnliche Wörter haben eine hohe Distanz.
Der Algorithmus, welcher die Ähnlichkeit der Wörter bestimmt, macht Gebrauch von der Distributional Hypthesis.
Dieser besagt, dass Wörter, welche im gleichen Kontext verwendet werden, eine ähnliche Semantik besitzen.
Hermit wird also die Ähnlichkeit der Wörter bestimmt.
Dieses Verfahren wird nun sowohl auf den Code angewendet als auch auf die Softwareentwicklungs-Artefakte.\\

In dem Paper "Information Retrieval Models for Recovering Traceability Links between Code and Documentation" verwenden Antoniol et. al. einen ähnlichen Ansatz, wie Ye et. al.
Auch hier werden Word Embeddings verwendet um Softwareentwicklungs-Artefakte gegen den Code zu matchen.
Hier durchlaufen die Artefakte und der Code zwei verschiedene Pipelines.
Die Wörter der Artefakte in natürlicher Sprache werden in lowercase umgewandelt.
Anschließend werden Stoppwörter entfernt.
Zuletzt werden Flexionen entfernt.
Aus dem Code werden zunächst Identifier extrahiert.
Identifier, welche mehrere Wörter unter Verwendung von CamelCase oder snake\_case beinhalten, werden in die einzelnen Wörter aufgeteilt.
Anschließend werden die Identifier auf die gleiche Art und Weise normalisiert, wie die Wörter der Softwareentwicklungs-Artefakte.
Dann erfolgt sowohl für die Identifier als auch für die Wörter aus den Artefakten die Indizierung, also die Umwandlung in Word Embeddings.

\section{Abgrenzungen}
Diese Arbeit behandelt keine Large Language Models, wie GPT.