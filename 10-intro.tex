\chapter{Einleitung}
Für die tägliche Arbeit benötigt ein Softwareentwickler Informationen, welche über den Code, an dem er arbeitet, hinausgehen.
Um an diese Informationen zu kommen kann der Softwareentwickler eine Person suchen, welche ihm die gewünschte Information geben kann.
Diese Person kann er im Projekt finden, oder über Websites, wie StackOverflow.
Darüber hinaus wird in vielen Projekten eine Wissensdatenbank angelegt, welche Informationen enthält, welche spezifisch für das Projekt sind.
Eine solche Wissensdatenbank ist Confluence.
Sie bietet eine Suchfunktion, welche es dem Softwareentwickler erleichtern soll, die gewünschten Informationen zu finden.
Beispiele für Informationen sind die Spezifikationen oder Dokumentationen eines Teiles der Software, mit welcher der Softwareentwickler gerade arbeitet.
Oder aber auch Best-Practices, Guides, oder Informationen darüber, wie die Software gestartet oder ausgeliefert wird.
Auch Informationen über den Projektplan sind für einen Softwareentwickler von Bedeutung.
Aber nicht immer finden Softwareentwickler die gewünschten Informationen mithilfe der Suchfunktion.
Ziel dieser Arbeit soll es sein, mithilfe von Wissen über Suchalgorithmen und Algorithmen aus dem Natural Language Processing zu zeigen, wie sich bestehende Suchfunktionen verbessern lassen.\\

Software, wie chatGPT\footnote{https://openai.com/blog/chatgpt} zeigt, dass Large Language Models eine valide Möglichkeit zur Information Extraction sind.
Es ist denkbar, dass Suchfunktionen für Softwareentwickler durch Large Language Models verbessert werden können.
Auch die Verwendung von vorgefertigten semantischen Netzen, welche in Knowledge Bases, wie DBPedia\footnote{https://www.dbpedia.org/} zu finden sind, sind als Lösung für dieses Problem denkbar (\cite{1644735}).
Sowohl die Verwendung von semantischen Netzen als auch die Verwendung von Vektordatenbanken kann als semantische Suche verstanden werden.
Später soll noch einmal auf den genauen Unterschied zwischen den beiden Methoden eingegangen werden.
In dieser Arbeit soll es lediglich um die Verwendung von Vektordatenbanken gehen.

\section{Vorgehensweise}
Die Gründe, warum eine gewünschte Information schwierig zu finden ist, sind vielzählig.
Manchmal kennt der Softwareentwickler nicht das genaue Wording, um die gewünschten Informationen zu finden.
Manchmal ist das Abstraktionslevel der gefundenen Informationen nicht das, welches sich der Softwareentwickler gewünscht hat.
Beispielsweise, wenn eine allgemeine Definition von Domänenobjekten gesucht wird, aber eine Spezifikation eines Anwendungsfalls gefunden wird, in welchem das Domänenobjekt lediglich erwähnt wird.
Es werden folgende Teilschritte durchlaufen, um die Suchfunktion von Wissensdatenbanken, wie Confluence, zu verbessern:
\begin{itemize}
   \item \textbf{Definition von Anwendungsfällen:}
         Es werden zuerst Anwendungsfälle definiert.
         Damit wird das Problem der Qualität einer Suchfunktion heruntergebrochen in Teilprobleme.
         Die Anwendungsfälle beschreiben die konkreten Situationen, in welchen ein Softwareentwickler eine Suche nutzen könnte.
         Das hilft später dabei mehrere Suchfunktionen miteinander vergleichen zu können.
         Denn anhand der Anwendungsfälle können realistische Sucheingaben definiert werden.
         Diese Sucheingaben können an zwei verschiedene Suchfunktionen übergeben werden.
         Anschließend können die gefundenen Ergebnisse verglichen werden.
         Die genaue Vorgehensweise für diesen Vergleich wird in \myRef{Kapitel}{chap:evaluationsmethoden} und \myRef{Kapitel}{chap:vergleich-der-suchfunktionen} erklärt.
         Außerdem bietet die Aufteilung in Anwendungsfälle bereits Aufschluss über die möglichen Verbesserungen, welche gemacht werden können.
         Hierauf wird in Kapitel "Erklärung des theoretischen Hintergrunds" und "Implementierung" weiter eingegangen.
   \item \textbf{Erklärung des theoretischen Hintergrunds:}
         Es wird die Theorie für die Implementierung einer Suchfunktion erläutert.
         Hier wird erklärt, welche Suchfunktionen es gibt.
         Außerdem werden Verfahren zur Indizierung von Dokumenten erklärt.
         Darüber hinaus werden NLP-Techniken erläutert, mit welchen Informationen aus gefundenen Dokumenten extrahiert werden können.
   \item \textbf{Implementierung:}
         Es wird eine neue Suchfunktion anhand der Informationen des theoretischen Hintergrunds implementiert.
         Es wird die Weaviate\footnote{https://weaviate.io/} Vektordatenbank verwendet, um Dokumente zu indizieren.
   \item \textbf{Herausarbeitung von Evaluationsmethoden und -Kriterien:}
         Es werden Methoden für die Bewertung herausgearbeitet.
         Damit wird die Frage beantwortet, wann eine Suchfunktion \textit{gut} ist.
         Das hier erläuterte Wissen wird für die Durchführung der Studie benötigt.
   \item \textbf{Durchführung einer Studie:}
         Um festzustellen, ob die Implementierung eine Verbesserung darstellt, muss eine Studie durchgeführt werden.
         Aufgrund des Scopes der Arbeit wird nur eine rudimentäre Studie durchgeführt.
         Die Ergebnisse werden dargestellt und diskutiert.
         Dabei wird auch darauf eingegangen, an welchen Stellen die Studie weiter ausgearbeitet werden muss, um präzise Ergebnisse liefern zu können.
         Außerdem wird der Versuchsaufbau beschrieben und die gemessenen Daten.
         Die Ergebnisse werden interpretiert und es wird ein Schluss gezogen.
\end{itemize}

\section{Verwandte Arbeiten}
Es gibt einige Arbeiten, welche die gleichen oder sehr ähnliche Probleme adressieren.
Die verschiedenen Herangehensweisen werden in diesem Kapitel erläutert.
Zuerst wird der Begriff Traceability behandelt, und wie diese genutzt wird, um Suchfunktionen zu verbessern.
Es folgt eine Übersicht über Arbeiten, welche sich mit Question Answering beschäftigen.
Dann folgt eine Übersicht über Arbeiten, welche sich mit der Evaluierung von Suchfunktionen auseinandersetzen.

% Traceability
Traceability bedeutet, dass sich von einer Stelle im Code, auf die entsprechenden Stellen in anderen Artefakten zurückschließen lässt.
Ein Anwendungsfall für eine solche Traceability-Funktionalität ist \textit{Feature Location}, also das Finden der Spezifikation eines Features, wenn nur der Code vorhanden ist.
Analog dazu ist \textit{Bug Localization} ein Anwendungsfall zum Auffinden von Stellen im Code, welche mit einem Bug zusammenhängen.
Zur Herstellung von Traceability zwischen Code und Dokumentation gibt es verschiedene Ansätze.
Haiduc et. al. schlagen ein System zur Verbesserung von Sucheingaben vorgeschlagen (\cite{Haiduc_Bavota_Marcus_Oliveto_DeLucia_Menzies_2013}).
Das System verwendet Query Reformulations, um die Traceability herzustellen.
Query Reformulation bedeutet, dass das System den Softwareentwickler bei der Eingabe einer Suchanfrage zur Suche nach den passenden Artefakten unterstützt.
Dazu gibt der Softwareentwickler zunächst eine Suchanfrage ein, und markiert diejenigen Ergebnisse, welche am relevantesten für ihn sind.
Auf Grundlage der gewählten Ergebnisse und mithilfe eines Machine Learning Algorithmus werden nun Vorschläge für eine verbesserte Suchanfrage gemacht.
Dabei gibt es verschiedene Strategien.
Wenn der Softwareentwickler zu Beginn eine sehr lange Suchanfrage eingegeben hat, dann kann das System eine Reduktion der Suchanfrage vorschlagen.
Hat der Softwareentwickler dagegen lediglich einen Suchbegriff angegeben, so kann das System eine Erweiterung der Suchbegriffe vorschlagen.
Dazu greift das System auf Synonyme des eingegebenen Suchbegriffes zurück.\\

Ye et. al. beschreiben, wie Word Embeddings dazu verwendet werden können, um Traceability zwischen Code und anderen Softwareentwicklungs-Artefakten herzustellen.
Word Embeddings sind eine Datenstruktur, welche einem Wort einen Vektor in einem n-dimensionalen Raum zuweist.
Anhand dieses Vektors kann die Ähnlichkeit zwischen Wörtern beschrieben werden.
Ähnliche Wörter haben eine geringe Distanz im n-dimensionalen Raum.
Unähnliche Wörter haben eine hohe Distanz.
Der Algorithmus, welcher die Ähnlichkeit der Wörter bestimmt, macht Gebrauch von der Distributional Hypothesis (\cite{Harris_1954}).
Dieser besagt, dass Wörter, welche im gleichen Kontext verwendet werden, eine ähnliche Semantik besitzen.
Hermit wird also die Ähnlichkeit der Wörter bestimmt.
Dieses Verfahren wird nun sowohl auf den Code angewendet als auch auf die Softwareentwicklungs-Artefakte (\cite{Ye_Shen_Ma_Bunescu_Liu_2016}).\\

Antoniol et. al. verwenden einen ähnlichen Ansatz, wie Ye et. al.
Auch hier werden Word Embeddings verwendet um Softwareentwicklungs-Artefakte gegen den Code zu matchen.
Hier durchlaufen die Artefakte und der Code zwei verschiedene Pipelines.
Die Wörter der Artefakte in natürlicher Sprache werden in lowercase umgewandelt.
Anschließend werden Stoppwörter entfernt.
Zuletzt werden Flexionen entfernt.
Aus dem Code werden zunächst Identifier extrahiert.
Identifier, welche mehrere Wörter unter Verwendung von CamelCase oder snake\_case beinhalten, werden in die einzelnen Wörter aufgeteilt.
Anschließend werden die Identifier auf die gleiche Art und Weise normalisiert, wie die Wörter der Softwareentwicklungs-Artefakte.
Dann erfolgt sowohl für die Identifier als auch für die Wörter aus den Artefakten die Indizierung, also die Umwandlung in Word Embeddings (\cite{Antoniol_Canfora_Casazza_DeLucia_2000}).
Treude et. al. entwickeln eine Oberfläche, welche die Suche von \textit{Tasks} ermöglicht.
Damit soll ebenfalls Traceability zwischen Code und Dokumentation hergestellt werden.
Dabei ist unter Task eine Operation im Code zu verstehen.
Sie beschreiben einen Task als Verben, welche mit einem direkten Objekt oder einer Präposition in Verbindung stehen.
Die Autoren nennen die Phrasen \textit{get iterator} und \textit{get iterator for collection} als Beispiele.
Die Software analysiert nun die gesamte Dokumentation und extrahiert Tasks.
Die Tasks werden in einen Index geschrieben, sodass der Softwareentwickler nach ihnen suchen kann (\cite{Treude_Sicard_Klocke_Robillard_2015}).\\

% Question Answering
Neben der Traceability zwischen Code und Dokumentation ist das Question Answering ein Ansatz zur Verbesserung von Suchfunktionen.
Suchfunktionen sind Document Retrieval Systeme.
Sie liefern Dokumente, welche zu der Sucheingabe des Nutzers passen.
Document Retrieval Systeme sind eine Unterkategorie von Information Retrieval Systemen.
Information Retrieval Systeme liefern auf Anfrage Informationen an den Nutzer.
Im Fall einer Suchfunktion werden Dokumente geliefert, welche diese Information beinhalten.
Mithilfe der Dokumente ist der Ort, an dem sich die, vom Nutzer gewünschte, Information befindet eingegrenzt.
Nichtsdestotrotz muss der Nutzer aus dieser Eingrenzung die gewünschte Information manuell extrahieren.
Ganz im Gegensatz zu Question Answering Systemen.
Zhang et. al. untersuchen verschiedene Herangehensweisen zur Implementierung von Open-Domain Question Answering Systemen (\cite{Zhang_Chen_Xu_Cao_Chen_Cohn_Fang_2023}).
Open-Domain Question Answering Systeme beantworten allgemeine Fragen eines Nutzers, z.B. basierend auf Informationen von Wikipedia.
Closed-Domain Question Answering Systeme beantworten dagegen Fragen im Kontext einer spezifischen Domäne, z.B. basierend auf unternehmensinternen Informationen.\\
% TODO: closed-domain sentence transformer transformer zu verwandten arbeiten hinzufügen (fine-tuned transformers)

% TODO: Informationen lassen sich auch anreichern: NER etc. (NLP Techniken)
% TODO: Informationen lassen sich aufbereiten: RAG

% Messung von Performance
% TODO: Trec und Benchmarks hinzufügen
Für die Messung der Performance einer Suchfunktion gibt es verschiedene Metriken.
Metriken können systemspezifisch sein, nutzerspezifisch.
Systemspezifische Metriken messen die Performance anhand objektiver Kriterien, welche an dem System gemessen werden können.
nutzerspezifische Metriken messen die Performance dagegen anhand subjektiver Kriterien.
Die Messung erfordert Probanden, welche die Suchfunktion verwenden.
Die Probanden legen die Performance der Suchfunktion anhand der zu betrachtenen subjektiven Kriterien fest.
Clarke und Willet messen die Qualität von Suchfunktionen des World Wide Webs anhand des Recalls (\cite{Clarke_Willett_1997}).
Um dies zu ermöglichen wird ein Datensatz generiert, welcher Sucheingaben beinhaltet, sowie alle relevanten Dokumente für eine Sucheingabe.
Bar-Ilan verwendet die gleichen Metriken (\cite{Bar-Ilan_2002}).
Hier wird darüber hinaus auf die Problematik der Messung des Recalls eingegangen.
Es wird erläutert, dass zur Messung des Recalls a-priori bestimmt werden muss, welche Dokumente als relevant für eine gegebene Sucheingabe erachtet werden sollten.
Gordon und Pathak behaupten, dass die Bestimmung der Relevanz lediglich dem Nutzer mit dem Bedürfnis nach der Information zu überlassen ist (\cite{Gordon_Pathak_1999}).
Voorhees und Harman behaupten, dass die Bestimmung der Relevanz durch ein Experten-Panel durchgeführt werden sollte (\cite{Voorhees_Harman_2001}).
Sirotkin betrachtet verschiedene Ansätze zur Messung der Performance von Suchfunktionen (\cite{Sirotkin_2012}).
Neben den bereits genannten Metriken von Precision und Recall werden andere Metriken zur Messung der Performance einer Suchfunktion genannt, wie Mean Reciprocal Rank und Maximal Marginal Relevance.\\
