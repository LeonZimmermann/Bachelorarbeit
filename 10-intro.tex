\chapter{Einleitung}
Für die tägliche Arbeit benötigt ein Softwareentwickler Informationen, welche über den Code, an dem er arbeitet, hinausgehen.
Um an diese Informationen zu kommen kann der Softwareentwickler eine Person suchen, welche ihm die gewünschte Information geben kann.
Diese Person kann er im Projekt finden, oder über Websites, wie StackOverflow.
Darüber hinaus wird in vielen Projekten eine Wissensdatenbank angelegt, welche Informationen enthält, welche spezifisch für das Projekt sind.
Eine solche Wissensdatenbank ist Confluence.
Sie bietet eine Suchfunktion, welche es dem Softwareentwickler erleichtern soll, die gewünschten Informationen zu finden.
Beispiele für Informationen sind die Spezifikationen oder Dokumentationen eines Teiles der Software, mit welcher der Softwareentwickler gerade arbeitet.
Oder aber auch Best-Practices, Guides, oder Informationen darüber, wie die Software gestartet oder ausgeliefert wird.
Auch Informationen über den Projektplan sind für einen Softwareentwickler von Bedeutung.
Aber nicht immer finden Softwareentwickler die gewünschten Informationen mithilfe der Suchfunktion.
Ziel dieser Arbeit soll es sein, mithilfe von Wissen über Suchalgorithmen und Algorithmen aus dem Natural Language Processing zu zeigen, wie sich bestehende Suchfunktionen verbessern lassen.\\

Software, wie chatGPT\footnote{https://openai.com/blog/chatgpt} zeigt, dass Large Language Models eine valide Möglichkeit zur Information Extraction sind.
Es ist denkbar, dass Suchfunktionen für Softwareentwickler durch Large Language Models verbessert werden können.
Auch die Verwendung von vorgefertigten semantischen Netzen, welche in Knowledge Bases, wie DBPedia\footnote{https://www.dbpedia.org/} zu finden sind, sind als Lösung für dieses Problem denkbar.\cite{1644735}
Sowohl die Verwendung von semantischen Netzen als auch die Verwendung von Vektordatenbanken kann als semantische Suche verstanden werden.
Später soll noch einmal auf den genauen Unterschied zwischen den beiden Methoden eingegangen werden.
In dieser Arbeit soll es lediglich um die Verwendung von Vektordatenbanken gehen.

\section{Vorgehensweise}
Die Gründe, warum eine gewünschte Information schwierig zu finden ist, sind vielzählig.
Manchmal kennt der Softwareentwickler nicht das genaue Wording, um die gewünschten Informationen zu finden.
Manchmal ist das Abstraktionslevel der gefundenen Informationen nicht das, welches sich der Softwareentwickler gewünscht hat.
Beispielsweise, wenn eine allgemeine Definition von Domänenobjekten gesucht wird, aber eine Spezifikation eines Anwendungsfalls gefunden wird, in welchem das Domänenobjekt lediglich erwähnt wird.
Es werden folgende Teilschritte durchlaufen, um die Suchfunktion von Wissensdatenbanken, wie Confluence, zu verbessern:
\begin{itemize}
   \item \textbf{Definition von Anwendungsfällen:}
         Es werden zuerst Anwendungsfälle definiert.
         Damit wird das Problem der Qualität einer Suchfunktion heruntergebrochen in Teilprobleme.
         Die Anwendungsfälle beschreiben die konkreten Situationen, in welchen ein Softwareentwickler eine Suche nutzen könnte.
         Das hilft später dabei mehrere Suchfunktionen miteinander vergleichen zu können.
         Denn anhand der Anwendungsfälle können realistische Suchanfragen definiert werden.
         Diese Suchanfragen können an zwei verschiedene Suchfunktionen übergeben werden.
         Anschließend können die gefundenen Ergebnisse verglichen werden.
         Die genaue Vorgehensweise für diesen Vergleich wird in \myRef{Kapitel}{chap:evaluationsmethoden} und \myRef{Kapitel}{chap:vergleich-der-suchfunktionen} erklärt.
         Außerdem bietet die Aufteilung in Anwendungsfälle bereits Aufschluss über die möglichen Verbesserungen, welche gemacht werden können.
         Hierauf wird in den Teilschritten "Erklärung des theoretischen Hintergrunds" und "Implementierung" weiter eingegangen.
   \item \textbf{Herausarbeitung von Evaluationsmethoden und -Kriterien:}
         Es werden Methoden für die Bewertung herausgearbeitet.
         Damit wird die Frage beantwortet, wann eine Suchfunktion \textit{gut} ist.
         Das hier erläuterte Wissen wird für die Durchführung der Studie benötigt.
   \item \textbf{Erklärung des theoretischen Hintergrunds:}
         Es wird die Theorie für die Implementierung einer Suchfunktion erläutert.
         Hier wird erklärt, welche Suchfunktionen es gibt.
         Außerdem werden Verfahren zur Indizierung von Dokumenten erklärt.
         Darüber hinaus werden NLP-Techniken erläutert, mit welchen Informationen aus gefundenen Dokumenten extrahiert werden können.
   \item \textbf{Implementierung:}
         Es wird eine neue Suchfunktion anhand der Informationen des theoretischen Hintergrunds implementiert.
         Es wird die Weaviate\footnote{https://weaviate.io/} Vektordatenbank verwendet, um Dokumente zu indizieren.
   \item \textbf{Durchführung einer Studie:}
         Um festzustellen, ob die Implementierung eine Verbesserung darstellt, muss eine Studie durchgeführt werden.
         Aufgrund des Scopes der Arbeit wird nur eine rudimentäre Studie durchgeführt.
         Die Ergebnisse werden dargestellt und diskutiert.
         Dabei wird auch darauf eingegangen, an welchen Stellen die Studie weiter ausgearbeitet werden muss, um präzise Ergebnisse liefern zu können.
         Außerdem wird der Versuchsaufbau beschrieben und die gemessenen Daten.
         Die Ergebnisse werden interpretiert und es wird ein Schluss gezogen.
\end{itemize}

\section{Verwandte Arbeiten}
Es gibt einige Arbeiten, welche die gleichen oder sehr ähnliche Probleme adressieren.\\

So wird in \textit{Automatic Query Reformulations for Text Retrieval in Software Engineering} von Haiduc et. al. ein System zur Verbesserung von Suchanfragen vorgeschlagen.
Ausgangspunkt für das Paper ist das Problem der Traceability zwischen Code und anderen Softwareentwicklungs-Artefakten.
Traceability bedeutet, dass sich von einer Stelle im Code, auf die entsprechenden Stellen in anderen Artefakten zurückschließen lässt.
Ein Anwendungsfall für eine solche Traceability-Funktionalität ist "Feature Location", also das finden der Spezifikation eines Features, wenn nur der Code vorhanden ist.
Das System, welches von Haiduc et. al. vorgeschlagen wird, verwendet Query Reformulations, um die Traceability herzustellen.
Query Reformulation bedeutet, dass das System den Softwareentwickler bei der Eingabe einer Suchanfrage zur Suche nach den passenden Artefakten unterstützt.
Dazu gibt der Softwareentwickler zunächst eine Suchanfrage ein, und markiert diejenigen Ergebnisse, welche am relevantesten für ihn sind.
Auf Grundlage der gewählten Ergebnisse und mithilfe eines Machine Learning Algorithmus werden nun Vorschläge für eine verbesserte Suchanfrage gemacht.
Dabei gibt es verschiedene Strategien.
Wenn der Softwareentwickler zu Beginn eine sehr lange Suchanfrage eingegeben hat, dann kann das System eine Reduktion der Suchanfrage vorschlagen.
Hat der Softwareentwickler dagegen lediglich einen Suchbegriff angegeben, so kann das System eine Erweiterung der Suchbegriffe vorschlagen.
Dazu greift das System auf Synonyme des eingegebenen Suchbegriffes zurück.\cite{Haiduc_Bavota_Marcus_Oliveto_DeLucia_Menzies_2013}\\

In dem Paper \textit{From Word Embeddings To Document Similarities for Improved Information Retrieval in Software Engineering} von Ye et. al. wird beschrieben, wie Word Embeddings dazu verwendet werden können, um Traceability zwischen Code und anderen Softwareentwicklungs-Artefakten herzustellen.
Word Embeddings sind eine Datenstruktur, welche einem Wort einen Vektor in einem n-dimensionalen Raum zuweist.
Anhand dieses Vektors kann die Ähnlichkeit zwischen Wörter beschrieben werden.
Ähnliche Wörter haben eine geringe Distanz im n-dimensionalen Raum.
Unähnliche Wörter haben eine hohe Distanz.
Der Algorithmus, welcher die Ähnlichkeit der Wörter bestimmt, macht Gebrauch von der Distributional Hypthesis.
Dieser besagt, dass Wörter, welche im gleichen Kontext verwendet werden, eine ähnliche Semantik besitzen.
Hermit wird also die Ähnlichkeit der Wörter bestimmt.
Dieses Verfahren wird nun sowohl auf den Code angewendet als auch auf die Softwareentwicklungs-Artefakte.\cite{Ye_Shen_Ma_Bunescu_Liu_2016}\\

In dem Paper \textit{Information Retrieval Models for Recovering Traceability Links between Code and Documentation} verwenden Antoniol et. al. einen ähnlichen Ansatz, wie Ye et. al.
Auch hier werden Word Embeddings verwendet um Softwareentwicklungs-Artefakte gegen den Code zu matchen.
Hier durchlaufen die Artefakte und der Code zwei verschiedene Pipelines.
Die Wörter der Artefakte in natürlicher Sprache werden in lowercase umgewandelt.
Anschließend werden Stoppwörter entfernt.
Zuletzt werden Flexionen entfernt.
Aus dem Code werden zunächst Identifier extrahiert.
Identifier, welche mehrere Wörter unter Verwendung von CamelCase oder snake\_case beinhalten, werden in die einzelnen Wörter aufgeteilt.
Anschließend werden die Identifier auf die gleiche Art und Weise normalisiert, wie die Wörter der Softwareentwicklungs-Artefakte.
Dann erfolgt sowohl für die Identifier als auch für die Wörter aus den Artefakten die Indizierung, also die Umwandlung in Word Embeddings.\cite{Antoniol_Canfora_Casazza_DeLucia_2000}\\

In dem Paper \textit{TaskNav: Task-based Navigation of Software Documentation} von Treude et. al. geht es um die Entwicklung einer Oberfläche, welche die Suche von \textit{Tasks} ermöglicht.
Dabei ist unter Task eine Operation im Code zu verstehen.
Das Paper beschreibt einen Task als Verben, welche mit einem direkten Objekt oder einer Präposition in Verbindung stehen.
Die Autoren nennen die Phrasen \textit{get iterator} und \textit{get iterator for collection} als Beispiele.
Die Software analysiert nun die gesamte Dokumentation und extrahiert Tasks.
Die Tasks werden in einen Index geschrieben, sodass der Softwareentwickler nach ihnen suchen kann. 
So wie die vorherigen Paper soll auch dieses Paper eine Brücke zwischen Dokumentation und Code schaffen.\cite{Treude_Sicard_Klocke_Robillard_2015}