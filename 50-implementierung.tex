\chapter{Implementierung der neuen Suchfunktion}
\label{chap:implementierung}
In diesem Kapitel wird die Implementierung der neuen Suchfunktion dargestellt.
Die Implementierung verwendet eine Vektordatenbank, welche eine semantische Suche ermöglicht.
Es wird die Vektordatenbank Weaviate verwendet.

\section{Aufsetzen der Vektordatenbank Weaviate}
Für das Aufsetzen von Weaviate werden zwei Komponenten benötigt.
Zum einen die Vektordatenbank selbst.
Zum anderen ein Transformer, welcher Text entgegennimmt, und diese in Vektoren umwandelt, sodass diese in der Datenbank gespeichert werden können.
Um die beiden Komponenten aufzusetzen wird Docker verwendet.
Das entsprechende docker-compose.yml File ist im Anhang zu finden.
Hier werden die beiden Komponenten definiert.
Unter \textit{t2v-transformers} wird der Transformer konfiguriert.
Es wird das Image eines bereits vortrainierten Transformers verwendet.
Unter \textit{weaviate} wird die Datenbank konfiguriert.
Hier wird mithilfe von den Environment-Variablen \textit{$DEFAULT\_VECTORIZER\_MODULE$}, \textit{$ENABLE\_MODULES$} und \textit{$TRANSFORMERS\_INFERENCE\_API$} konfiguriert, welcher Transformer verwendet werden soll.
So wird konfiguriert, dass der Transformer der anderen Komponente verwendet werden soll.\\

Neben den beiden Docker-Containern für die semantische Suche wird eine Spring Boot Anwendung in einem Docker Container mitdeployt.
Die Spring Boot Anwendung verwendet Kotlin und Gradle.
Mithilfe der Dependency \textit{io.weaviate:client:4.0.1} wird die Client API von Weaviate verwendet.
So wird nun eine Verbindung zu der Vektordatenbank aufgebaut.
Diese beinhaltet zu diesem Zeitpunkt noch keine Daten.
Bevor die Daten in die Datenbank eingespielt werden, muss das Schema der Daten angegeben werden.
Der entsprechende Code ist ebenfalls im Anhang zu finden.
Es wird eine Klasse \textit{Document} definiert.
Diese Klasse beinhaltet die Properties \textit{documentUrl}, \textit{h1}, \textit{h2} und \textit{p}.
Es werden in dieser Klasse also die URL des Dokuments, sowie die Inhalte aller h1-, h2 und p-Tags gespeichert.
Außerdem wird als Vectorizer \textit{text2vec-transformers} konfiguriert.\\

\section{Einspielen der Daten in Weaviate}
\label{chap:einspielen-der-daten-in-weaviate}
Um nun die Daten aus Confluence in Weaviate einzuspielen, werden zuerst die Daten aus Confluence exportiert.
Beim Export von Confluence-Seiten werden HTML-Dateien generiert.
Es werden keine CSS-, JavaScript- oder Bilddateien generiert.
Die HTML-Dateien werden preprocessed, um dem zuvor definierten Schema zu entsprechen.
Es werden zuerst mithilfe eines Abstract Syntax Trees alle Inhalte von h1-, h2- und p-Tags herausgefiltert.
Anschließend werden Punctuations und Stopwords entfernt und die Inhalte druchlaufen einen Tokenizer und einen Stemmer.
Punctuations sind Zeichen, wie die folgenden: \textit{.,;:}.
Stopwords sind Wörter, welche für einen Leser notwendig sind, aber für die Verarbeitung durch einen Algorithmus als unwichtig erachtet werden (\cite{Sarica_Luo_2021}).
Beispiele für Stopwords sind \textit{aber, denn, der}.
Ein Tokenizer trennt einen Text in einzelne Wörter auf.
Aus einem Text, wie \textit{das deployment erfolgt durch ein bash-skript} wird also ein Array, welches folgendermaßen aussieht:\\

\(["das", "deployment", "erfolgt", "durch", "ein", "bash", "skript"]\).\\

Ein Stemmer bestimmt den Wortstamm für die einzelnen Wörter auf Basis von Grammatikregeln.
Die Software verwendet den Porter-Stemmer-Algorithmus.
Aus dem Wort \textit{deployment} wird dadurch beispielsweise \textit{deploy}.
Duplikate von Wörtern werden anschließend verworfen.
Alle Inhalte, welche in h1-Tags stehen, werden konkateniert und einem Datenfeld der Vektordatenbank gespeichert.
Das gleiche gilt für die übrigen Tags.
Nachdem die Inhalte das Preprocessing durchlaufen haben, werden sie in die Datenbank eingespielt.\\

In \myRef{Kapitel}{chap:vektorindizes} wurde bereits von Performancegründen gesprochen, aus denen das Preprocessing durchgeführt wird.
Da nun die einzelnen Schritte des Preprocessings erklärt wurden, kann auch erklärt werden, warum das Preprocessing die Performance beim indizieren erhöht.
Zuallererst werden viele Wörter gänzlich verworfen, weil sie Stopwords sind.
Durch den Stemmer werden anschließend ähnliche Wörter zusammengruppiert.
Die Wörter \textit{Heizung} und \textit{heizen} stammen beide vom gleichen Wortstamm \textit{heiz}.
Das bedeutet, dass aus zwei verschiedenen Wörtern, welche beide indiziert werden müssen, ein einziges Wort gemacht wird.
Denn am Ende werden Duplikate, wie bereits erwähnt, verworfen.
Die Anzahl der Wörter, welche indiziert werden müssen, wird dadurch reduziert, und damit auch die Last auf dem Transformer, welche die Vektoren für die Wörter berechnen muss.

% \section{Die Konfiguration der Suchfunktionen}
% TODO: Auf Benchmark beziehen und erläutern, wie Weaviate konfiguriert war